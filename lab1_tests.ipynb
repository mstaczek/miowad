{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "26cd3a7a-909a-4209-8129-8c7a01fd0571",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 69451,
    "execution_start": 1646165449736,
    "source_hash": "a3bb51a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from MultiLayerPerceptron import NeuralNetwork, Layer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cb828058-f2ec-4874-af42-9497f2d64d12",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 69342,
    "execution_start": 1646165449781,
    "source_hash": "9b245b99",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network layers:\n",
      "\tLayer 1: Layer has 3 neurons (including 1 bias neuron) and activation function is 'linear function'\n",
      "\tLayer 2: Layer has 1 neurons (with no bias neuron) and activation function is 'linear function'\n",
      "Neural network weights:\n",
      "\tWeights 1: (3, 1) (input, output)\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n",
      "\n",
      "Input [20, 300]\n",
      "expected: [941.0]\n",
      "predicted: [941.0]\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "MyNet = NeuralNetwork(weights_random = False)\n",
    "MyNet.add(Layer(neurons_count=2))\n",
    "MyNet.add(Layer(neurons_count=1,activation_fun='linear',add_bias=False))\n",
    "MyNet.set_weights([np.array([[1],[2],[3]])])\n",
    "input_1 = [20,300]\n",
    "output_1 = MyNet.predict(input_1)\n",
    "output_1_expected = [941.]\n",
    "print(MyNet)\n",
    "print(f\"Input {input_1}\")\n",
    "print(f\"expected: {output_1_expected}\")\n",
    "print(f\"predicted: {output_1}\")\n",
    "assert(output_1 == output_1_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "20ee8c6f-bc6e-4db0-8ebe-81d78445d224",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 32286,
    "execution_start": 1646165449782,
    "source_hash": "b3ce59fc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network layers:\n",
      "\tLayer 1: Layer has 3 neurons (including 1 bias neuron) and activation function is 'linear function'\n",
      "\tLayer 2: Layer has 2 neurons (with no bias neuron) and activation function is 'sigmoid function'\n",
      "Neural network weights:\n",
      "\tWeights 1: (3, 2) (input, output)\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]]\n",
      "\n",
      "Input [10, 5]\n",
      "expected: [0.24069977, 0.00299319]\n",
      "predicted: [0.2406997676723526, 0.002993186672602314]\n"
     ]
    }
   ],
   "source": [
    "from MultiLayerPerceptron import NeuralNetwork, Layer\n",
    "import numpy as np\n",
    "\n",
    "# test 2\n",
    "np.random.seed(123)\n",
    "MyNet = NeuralNetwork()\n",
    "MyNet.add(Layer(neurons_count=2))\n",
    "MyNet.add(Layer(neurons_count=2,activation_fun='sigmoid',add_bias=False))\n",
    "input_1 = [10,5]\n",
    "output_1 = MyNet.predict(input_1)\n",
    "output_1_expected = [0.24069977, 0.00299319]\n",
    "print(MyNet)\n",
    "print(f\"Input {input_1}\")\n",
    "print(f\"expected: {output_1_expected}\")\n",
    "print(f\"predicted: {output_1}\")"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "a72fbcdf-0a1f-4adc-b5f3-c08a300123a8",
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
