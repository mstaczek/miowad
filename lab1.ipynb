{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Metody Inteligencji Obliczeniowej w Analizie Danych\n\n[Tasks](https://pages.mini.pw.edu.pl/~karwowskij/mioad/lab-sieci.html)\n\n### MLP Lab 1\n\nNa tych zajęciach należy zaimplementować sieć neuronową typu MLP, w której można ustawić: liczbę warstw, liczbę neuronów w każdej z warstw i wagi poszczególnych połączeń, w tym biasów. Sieć ma **używać sigmoidalnej funkcji** aktywacji. **Na wyjściu** dopuszczana jest funkcja **liniowa**.\n\nImplementacja sieci musi być przygotowana w taki sposób, żeby łatwo zmieniać:\n\n- Architekturę, to znaczy liczbę wejść, wyjść, neuronów w warstwach ukrytych. \n- Funkcję aktywacji.  \n\nTak przygotowaną implementację należy następnie wykorzystać do rozwiązania zadania regresji na dostarczonych danych. Parametry sieci należy dobrać ręcznie, tak aby uzyskać możliwie dobrze wyniki na zbiorach danych (zbudować po jednej sieci dla każdego zbioru):\n\nsquare-simple\nsteps-large\nRozważyć architektury sieci:\n\n- jedna warstwa ukryta, 5 neuronów,  \n- jedna warstwa ukryta, 10 neuronów,\n- dwie warstwy ukryte, po 5 neuronów każda.\n\nAby otrzymać 2 punkty MSE na [nieznormalizowanym] zbiorze testowym nie może przekraczać wartości 9.",
   "metadata": {
    "cell_id": "44b5a607-a1d8-4c16-a169-2f19ba376a74",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### TODO:\n\n- add asserts\n- create more tests",
   "metadata": {
    "cell_id": "01b431b8-fb3c-4683-9272-5562c201c2fd",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "40602327-1c7a-43fa-ac1c-b82ee29ca269",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42,
    "execution_start": 1646408765810,
    "source_hash": "385c81c6",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "from MultiLayerPerceptron import NeuralNetwork, Layer\nfrom itertools import chain\nimport pandas as pd\nimport numpy as np\n\ndef mse(real, pred):\n    return np.square(np.subtract(real,pred)).mean() ",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset 2: Square Simple",
   "metadata": {
    "cell_id": "a6004e85-e7d1-42fa-a537-f8274a1971c6",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "19ac30b4-d6eb-45f1-9938-6ed06e815fc1",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 50,
    "execution_start": 1646408765852,
    "source_hash": "84c2b957",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "df_train = pd.read_csv('data/regression/square-simple-training.csv').set_index(\"Unnamed: 0\")\ndf_test = pd.read_csv('data/regression/square-simple-test.csv').set_index(\"Unnamed: 0\")\nprint(df_train.head())\n\nx_train = [[x] for x in df_train.loc[:,\"x\"]]\ny_train = [y for y in df_train.loc[:,\"y\"]]\nx_test = [[x] for x in df_test.loc[:,\"x\"]]\ny_test = [y for y in df_test.loc[:,\"y\"]]",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "                   x           y\nUnnamed: 0                      \n1          -0.171543 -127.351580\n2           0.025201 -129.942844\n3          -1.368991   38.672367\n4           1.907390  197.432191\n5           0.011129 -129.988852\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Model 1: 1 hidden layer with 5 neurons",
   "metadata": {
    "cell_id": "70aaf871-e790-49e4-a2c0-152c9b76a8d9",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "260b0f75-78ae-40e2-93ab-98e062753188",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1646408765897,
    "source_hash": "a8fd83bb",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "net1_1_5_1 = NeuralNetwork(weights_random=False)\nnet1_1_5_1.add(Layer(neurons_count=1, add_bias=True))\nnet1_1_5_1.add(Layer(neurons_count=5, activation_fun=\"sigmoid\", add_bias=True))\nnet1_1_5_1.add(Layer(neurons_count=1, activation_fun=\"linear\", add_bias=False))\nnet1_1_5_1.set_weights(weights=[\\\n        np.array([[-2.9,-2.8897,-2.8897,-2.8897,-2.8897],\\\n                [-0.9733,-0.9733,-0.9733,-0.9733,0.9733]]),\\\n        np.array([[-339.16],\\\n                [502],\\\n                [502],\\\n                [502],\\\n                [502],\\\n                [1993]])])\nprint(net1_1_5_1)",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Neural network layers:\n\tLayer 1: Layer has 2 neurons (including 1 bias neuron) and activation function is 'linear function'\n\tLayer 2: Layer has 6 neurons (including 1 bias neuron) and activation function is 'sigmoid function'\n\tLayer 3: Layer has 1 neurons (with no bias neuron) and activation function is 'linear function'\nNeural network weights:\n\tWeights 1: (2, 5) (input, output)\n[[-2.9    -2.8897 -2.8897 -2.8897 -2.8897]\n [-0.9733 -0.9733 -0.9733 -0.9733  0.9733]]\n\tWeights 2: (6, 1) (input, output)\n[[-339.16]\n [ 502.  ]\n [ 502.  ]\n [ 502.  ]\n [ 502.  ]\n [1993.  ]]\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "518f9ebc-61e4-45d0-9201-1d450babfc28",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 38,
    "execution_start": 1646408765898,
    "source_hash": "dd22cbe8",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "y_train_pred_1 = net1_1_5_1.predict(x_train)\ny_train_pred_1 = list(chain.from_iterable(y_train_pred_1))\nmse_1_1 = mse(y_train_pred_1, y_train)\nprint(f\"MSE train is {round(mse_1_1,2)}\")",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "MSE train is 2.46\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d7c3dad9-296a-40c6-8373-7cd9f3465ca0",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1646408765936,
    "source_hash": "22d6a869",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "y_test_pred_1 = net1_1_5_1.predict(x_test)\ny_test_pred_1 = list(chain.from_iterable(y_test_pred_1))\nmse_1_2 = mse(y_test_pred_1, y_test)\nprint(f\"MSE test is {round(mse_1_2,2)}\")",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "MSE test is 2.26\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Model 2: 1 hidden layer with 10 neurons",
   "metadata": {
    "cell_id": "cee17e03-0ba4-474d-87f8-07ca14ec1a81",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "234df347-bfe1-4376-9da0-71429a538d00",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1646408765938,
    "source_hash": "6fdb2faa",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "net2_1_10_1 = NeuralNetwork(weights_random=False)\nnet2_1_10_1.add(Layer(neurons_count=1, add_bias=True))\nnet2_1_10_1.add(Layer(neurons_count=10, activation_fun=\"sigmoid\", add_bias=True))\nnet2_1_10_1.add(Layer(neurons_count=1, activation_fun=\"linear\", add_bias=False))\nnet2_1_10_1.set_weights(weights=[\\\n        np.array([[-2.8897,-2.8897,-2.8897,-2.8897,-2.8897,-2.8897,-2.8897,-2.8897,-2.8897,-2.8897],\\\n                [-0.9733,-0.9733,-0.9733,-0.9733,-0.9733,0.9733,0.9733,0.9733,0.9733,0.9733]]),\\\n        np.array([[-339.3],\\\n                [400],\\\n                [400],\\\n                [400],\\\n                [400],\\\n                [400],\\\n                [400],\\\n                [400],\\\n                [400],\\\n                [400],\\\n                [400]])])\nprint(net2_1_10_1)",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": "Neural network layers:\n\tLayer 1: Layer has 2 neurons (including 1 bias neuron) and activation function is 'linear function'\n\tLayer 2: Layer has 11 neurons (including 1 bias neuron) and activation function is 'sigmoid function'\n\tLayer 3: Layer has 1 neurons (with no bias neuron) and activation function is 'linear function'\nNeural network weights:\n\tWeights 1: (2, 10) (input, output)\n[[-2.8897 -2.8897 -2.8897 -2.8897 -2.8897 -2.8897 -2.8897 -2.8897 -2.8897\n  -2.8897]\n [-0.9733 -0.9733 -0.9733 -0.9733 -0.9733  0.9733  0.9733  0.9733  0.9733\n   0.9733]]\n\tWeights 2: (11, 1) (input, output)\n[[-339.3]\n [ 400. ]\n [ 400. ]\n [ 400. ]\n [ 400. ]\n [ 400. ]\n [ 400. ]\n [ 400. ]\n [ 400. ]\n [ 400. ]\n [ 400. ]]\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8fcf969e-423e-4fb6-a4a2-d18c1f5940e1",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1646408766004,
    "source_hash": "2a575812",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "y_train_pred_2 = net2_1_10_1.predict(x_train)\ny_train_pred_2 = list(chain.from_iterable(y_train_pred_2))\nmse_1_2 = mse(y_train_pred_2, y_train)\nprint(f\"MSE train is {round(mse_1_2,2)}\")",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "MSE train is 3.11\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a389a052-d24a-4d60-a86c-9baae466a34c",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1646408766005,
    "source_hash": "1a7566a5",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "y_test_pred_2 = net2_1_10_1.predict(x_test)\ny_test_pred_2 = list(chain.from_iterable(y_test_pred_2))\nmse_1_2 = mse(y_test_pred_2, y_test)\nprint(f\"MSE test is {round(mse_1_2,2)}\")",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "MSE test is 2.63\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset 2: Steps Large",
   "metadata": {
    "cell_id": "6cb1b0f3-8904-428b-8397-18c9bfcfe5f8",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "1fd127d0-1098-4fd1-8ed2-c5413b8b99e1",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 46,
    "execution_start": 1646408766005,
    "source_hash": "752dcdd6",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "df_train = pd.read_csv('data/regression/steps-large-training.csv').set_index(\"Unnamed: 0\")\ndf_test = pd.read_csv('data/regression/steps-large-test.csv').set_index(\"Unnamed: 0\")\nprint(df_train.head())\n\nx_train = [[x] for x in df_train.loc[:,\"x\"]]\ny_train = [y for y in df_train.loc[:,\"y\"]]\nx_test = [[x] for x in df_test.loc[:,\"x\"]]\ny_test = [y for y in df_test.loc[:,\"y\"]]",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "                   x   y\nUnnamed: 0              \n1          -1.481354 -80\n2           1.033264  80\n3          -0.076403   0\n4          -1.419785 -80\n5          -0.108398   0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Model 1: 2 hidden layers with 5 neurons each",
   "metadata": {
    "cell_id": "5d3fea08-a7fb-4600-af3a-498efb926fc2",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a5f7d55f-9b62-45cf-91a3-d344462aeae1",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1646408766049,
    "source_hash": "a779e47a",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "net3_1_5_1 = NeuralNetwork()\nnet3_1_5_1.add(Layer(neurons_count=1, add_bias=True))\nnet3_1_5_1.add(Layer(neurons_count=5, activation_fun='sigmoid', add_bias=True))\nnet3_1_5_1.add(Layer(neurons_count=1, activation_fun='linear', add_bias=False))\n\nb = -250\na = 500\nc = -80\nd = 80\ne = 80/2\n\nnet3_1_5_1.set_weights([\\\n        np.array([[-250,-750,-750,250,250],\\\n                [501,499.95,499.95,500.2,500.2]]),\\\n        np.array([[-80],\\\n                [80],\\\n                [40],\\\n                [40],\\\n                [40],\\\n                [40]])])\nprint(net3_1_5_1)",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "Neural network layers:\n\tLayer 1: Layer has 2 neurons (including 1 bias neuron) and activation function is 'linear function'\n\tLayer 2: Layer has 6 neurons (including 1 bias neuron) and activation function is 'sigmoid function'\n\tLayer 3: Layer has 1 neurons (with no bias neuron) and activation function is 'linear function'\nNeural network weights:\n\tWeights 1: (2, 5) (input, output)\n[[-250.   -750.   -750.    250.    250.  ]\n [ 501.    499.95  499.95  500.2   500.2 ]]\n\tWeights 2: (6, 1) (input, output)\n[[-80]\n [ 80]\n [ 40]\n [ 40]\n [ 40]\n [ 40]]\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0a59fef5-2a8a-4b02-bf54-0a15c0642f22",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 806,
    "execution_start": 1646408766099,
    "source_hash": "ad950854",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "y_train_pred_2 = net3_1_5_1.predict(x_train)\ny_train_pred_2 = list(chain.from_iterable(y_train_pred_2))\nmse_1_2 = mse(y_train_pred_2, y_train)\nprint(f\"MSE train is {round(mse_1_2,2)}\")",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": "MSE train is 4.14\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d8ce1367-5fee-4278-9578-ea9ab5ec8534",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 129,
    "execution_start": 1646408766915,
    "source_hash": "1ece4d2c",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "y_test_pred_2 = net3_1_5_1.predict(x_test)\ny_test_pred_2 = list(chain.from_iterable(y_test_pred_2))\nmse_1_2 = mse(y_test_pred_2, y_test)\nprint(f\"MSE test is {round(mse_1_2,2)}\")",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "MSE test is 3.58\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Results\n\nMSE for the `square simple` dataset is:  \n- train: 2.46\n- test: 2.26\n\nMSE for the `steps large` dataset is:  \n- train: 4.14\n- test: 3.58\n",
   "metadata": {
    "cell_id": "7213c921-8251-4443-bf67-0809a98035b3",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=96d48dca-8d08-48ed-b693-a040059620ca' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "b5b4072f-fbbd-41fa-be8b-1159e9f083c9",
  "interpreter": {
   "hash": "6553f9dcd9d8af4a6d8fef01a514c9a715cb88eedc2258fed476c62d27d9dcbf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 }
}